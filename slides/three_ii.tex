% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compatii\relax\makeatother 
\documentclass[10pt,t]{beamer}
\usefonttheme{professionalfonts}
\usefonttheme{serif}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../map2} % read refs from .aux file
\usepackage{xr}\externaldocument{../vs3} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Homomorphisms] % (optional, use only with long paper titles)
{Three.II Homomorphisms}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Homomorphisms}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Three.II.1 .....
\section{Definition}
%..........
\begin{frame}{Homomorphism}
\df[def:Homo]
\ExecuteMetaData[../map2.tex]{df:Homo}
\end{frame}




%..........
% \begin{frame}
% \ex
% The function $\map{h}{\polyspace_2}{\Re^2}$ given by
% \begin{equation*}
%   h(a+bx+cx^2)
%   =
%   \colvec{a+c \\ 0}
% \end{equation*}
% is a homomorphism. 
% (Note that it is neither one-to-one nor onto.)
% \pause
% Showing that it respects addition is routine.
% \begin{gather*}
%   h(\,(a_1+b_1x+c_1x^2)+(a_2+b_2x+c_2x^2)\,)      \\
%   \begin{align*}
%     \qquad
%     &=h(\,(a_1+a_2)+(b_1+b_2)x+(c_1+c_2)x^2\,)     \\
%     &=\colvec{a_1+a_2+c_1+c_2 \\ 0}                 \\
%     &=\colvec{a_1+c_1 \\ 0}+\colvec{a_2+c_2 \\ 0}   \\
%     &=h(a_1+b_1x+c_1x^2)+h(a_2+b_2x+c_2x^2)       
%   \end{align*}
% \end{gather*}
% \pause
% So is showing that it respects scalar multiplication.
% \begin{equation*}
%   r\cdot h(a+bx+cx^2)
%   =r\cdot\colvec{a+c \\ 0}  
%   =\colvec{ra+rc \\ 0}
%   =h(\,r(a+bx+cx^2)\,)
% \end{equation*}
% \end{frame}



%..........
\begin{frame}
\ex
Of these two maps $\map{h,g}{\Re^2}{\Re}$,
the first is a homomorphism while the second is not.
\begin{equation*}
  \colvec{x \\ y}\mapsunder{h} 2x-3y
  \qquad
  \colvec{x \\ y}\mapsunder{g} 2x-3y+1
\end{equation*}

\pause
The map $h$ respects addition
\begin{multline*}
  h(\colvec{x_1 \\ y_1}+\colvec{x_2 \\ y_2})
  =h(\colvec{x_1+x_2 \\ y_1+y_2})             
  =2(x_1+x_2)-3(y_1+y_2)                    \\
  =(2x_1-3y_1)+(2x_2-3y_2)
  =h(\colvec{x_1 \\ y_1})+h(\colvec{x_2 \\ y_2})
\end{multline*}
and scalar multiplication.
\begin{equation*}
  r\cdot h(\colvec{x \\ y})
  =r\cdot(2x-3y)
  =2rx-3ry
  =(2r)x-(3r)y
  =h(r\cdot\colvec{x \\ y})
\end{equation*}

\pause
In contrast, $g$ does not respect addition.
\begin{equation*} 
  g(\colvec{1 \\ 4}+\colvec{5 \\ 6})=-17
  \qquad
  g(\colvec{1 \\ 4})+g(\colvec{5 \\ 6})=-16
\end{equation*}
\end{frame}




%..........
\begin{frame}
We proved these two while studying isomorphisms.

\lm[le:HomoSendsZeroToZero]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:HomoSendsZeroToZero}

\lm[le:HomoPreserveLinCombo]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:HomoPreserveLinCombo}

\medskip
To verify that a map is a homomorphism the one that we use most often
is statement~(2). 

\pause
\ex
Between any two vector spaces the zero map $\map{Z}{V}{W}$ given by
$Z(\vec{v})=\zero_W$ is a linear map.
Using~(2): 
$Z(c_1\vec{v}_1+c_2\vec{v}_2)=\zero_W
   =\zero_W+\zero_W=c_1Z(\vec{v}_1)+c_2Z(\vec{v}_2)$.
\end{frame}




%..........
\begin{frame}
\ex
The \definend{inclusion map} $\map{\iota}{\Re^2}{\Re^3}$
\begin{equation*}
  \iota(\colvec{x  \\ y})
  =\colvec{x \\ y \\ 0}
\end{equation*}
is a homomorphism.
\begin{align*}
  \iota(c_1\cdot\colvec{x_1 \\ y_1}+c_2\cdot\colvec{x_2 \\ y_2})
  &=\iota(\colvec{c_1x_1+c_2x_2 \\ c_1y_1+c_2y_2})       \\
  &=\colvec{c_1x_1+c_2x_2 \\ c_1y_1+c_2y_2 \\ 0}      \\
  &=\colvec{c_1x_1 \\ c_1y_1 \\ 0}
   +\colvec{c_2x_2 \\ c_2y_2 \\ 0}                    \\
  &=c_1\cdot\iota(\colvec{x_1 \\ y_1})+c_2\cdot\iota(\colvec{x_2 \\ y_2})
\end{align*}
\end{frame}




% %..........
% \begin{frame}
% \ex
% Consider 
% this function $\map{h}{\polyspace_1}{\polyspace_1}$.
% \begin{equation*}
%   h(a+bx)=b+bx
% \end{equation*}
% Here are two examples of the action of this function: $1+2x\mapsto 2+2x$
% and $3-x\mapsto-1-x$. 

% \pause
% This is a linear map.
% \begin{multline*}
%   h(\,c_1\cdot (a_1+b_1x)+c_2\cdot(a_2+b_2x)\,)                  \\
%   \begin{aligned}
%     &=h(\,(c_1a_1+c_2a_2)+(c_1b_1+c_2b_2)x\,)       \\
%     &=(c_1b_1+c_2b_2)+(c_1b_1+c_2b_2)x          \\
%     &=(c_1b_1+c_1b_1x)+(c_2b_2+c_2b_2x)         \\
%     &=c_1\cdot h(a_1+b_1x)+c_2\cdot h(a_2+b_2x)
%   \end{aligned}
% \end{multline*}
% \end{frame}




%..........
\begin{frame}
\ex
The derivative
is the usual transformation of polynomial space
$\map{d/dx}{\polyspace_2}{\polyspace_1}$.
\begin{equation*}
  d/dx\,(ax^2+bx+c)=2ax+b
\end{equation*}
For instance, $d/dx\,(3x^2-2x+4)=6x-2$
and $d/dx\,(x^2+1)=2x$.

\pause
This map is a homomorphism.
\begin{multline*}
  d/dx\,\big(\,r_1(a_1x^2+b_1x+c_1)+r_2(a_2x^2+b_2x+c_2)\,\big)  \hspace*{5em}  \\
  \begin{aligned} 
    &=d/dx\,\big(\,(r_1a_1+r_2a_2)x^2+(r_1b_1+r_2b_2)x+(r_1c_1+r_2c_2)\,\big)   \\
    &=2(r_1a_1+r_2a_2)x+(r_1b_1+r_2b_2)   \\
    &=(2r_1a_1x+r_1b_1)+(2r_2a_2x+r_2b_2)   \\
    &=r_1\cdot d/dx\,(a_1x^2+b_1x+c_1)
      +r_2\cdot d/dx\,(a_2x^2+b_2x+c_2)
  \end{aligned}
\end{multline*}
\end{frame}



%..........
% \begin{frame}
% \ex
% The \definend{trace} of a square matrix 
% is the sum down the upper-left to lower-right diagonal.
% Thus
% $\map{\trace}{\matspace_{\nbyn{2}}}{\Re}$
% is this.
% \begin{equation*}
%   \trace(\begin{mat}
%     a &b \\
%     c &d
%   \end{mat})
%   =a+d
% \end{equation*}
% It is linear.
% \begin{multline*}
%   \trace(\,
%   r_1\cdot\begin{mat}
%     a_1 &b_1 \\
%     c_1 &d_1
%   \end{mat}
%   +
%   r_2\cdot\begin{mat}
%     a_2 &b_2 \\
%     c_2 &d_2
%   \end{mat}
%   \,)                                              \\
%   \begin{aligned}
%     &=\trace(
%       \begin{mat}
%         r_1a_1+r_2a_2 &r_1b_1+r_2b_2 \\
%         r_1c_1+r_2c_2 &r_1d_1+r_2d_2
%       \end{mat}
%       )                                       \\
%     &=(r_1a_1+r_2a_2)+(r_1d_1+r_2d_2)         \\
%     &=r_1(a_1+d_1)+r_2(a_2+d_2)               \\
%     &=r_1\cdot\trace(
%       \begin{mat}
%         a_1 &b_1 \\
%         c_1 &d_1
%       \end{mat}
%       )
%       +
%       r_2\cdot\trace(
%       \begin{mat}
%         a_2 &b_2 \\
%         c_2 &d_2
%       \end{mat}
%       )
%   \end{aligned} 
% \end{multline*}
% \end{frame}



%..........
\begin{frame}
\th[th:HomoDetActOnBasis]
\ExecuteMetaData[../map2.tex]{th:HomoDetActOnBasis}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis0}

\pause
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis1}
\end{frame}
\begin{frame}
\ExecuteMetaData[../map2.tex]{pf:HomoDetActOnBasis2}
\qed

\pause % \medskip
\df[df:ExtendedLinearly]
\ExecuteMetaData[../map2.tex]{df:ExtendedLinearly}
\end{frame}




%..........
\begin{frame}
\ex
Consider the action $\map{t_\Theta}{\Re^2}{\Re^2}$ of  
rotating all vectors in the plane through an
angle~$\Theta$.
These drawings show that this map satisfies the addition 
\begin{center}
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate_sum_before.pdf}}
  \qquad$\mapsunder{t_{\pi/6}}$\qquad
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate_sum_after.pdf}}
\end{center}
and scalar multiplication conditions
\begin{center}
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate_prod_before.pdf}}
  \qquad$\mapsunder{t_{\pi/6}}$\qquad
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate_prod_after.pdf}}
\end{center}
(they also suggest why we say linear maps ``preserve'' the operations).
We will develop the formula for $t_\Theta$.
\end{frame}
\begin{frame}
Fix a basis for the domain $\Re^2$; 
the standard basis $\stdbasis_2$ is convenient.
We want the basis vectors mapped as here.
\begin{equation*}
  \vcenteredhbox{\includegraphics{asy/three_ii_rotate_basis.pdf}}
  \qquad
  \colvec{1 \\ 0}\mapsto\colvec[r]{\cos\theta \\ \sin\theta}
  \quad
  \colvec{0 \\ 1}\mapsto\colvec[r]{-\sin\theta \\ \cos\theta}
  % \qquad
  % \vcenteredhbox{\includegraphics{asy/three_ii_rotate.pdf}}
\end{equation*}
\pause
Extend linearly. 
\begin{align*}
  t_{\theta}(\colvec{x \\ y})
  &=
  t_{\theta}(x\cdot\colvec{1 \\ 0}+y\cdot\colvec{0 \\ 1})  \\
  &=
  x\cdot t_{\theta}(\colvec{1 \\ 0})+y\cdot t_{\theta}(\colvec{0 \\ 1})  \\
  &=x\cdot\colvec[r]{\cos\theta \\ \sin\theta}
    +y\cdot\colvec[r]{-\sin\theta \\ \cos\theta}  \\
  &=\colvec{x\cos\theta-y\sin\theta \\ x\sin\theta+y\cos\theta}
\end{align*}
% \pause
% (This map is one-to-one and onto, so it is an automorphism.)
\end{frame}



%..........
\begin{frame}
\ex 
One basis of the space of quadratic polynomials $\polyspace_2$
is $B=\sequence{x^2,x,1}$.
We can define a map $\map{\text{eval}_3}{\polyspace_2}{\Re}$ 
by specifying its action on that basis
\begin{equation*}
  x^2\mapsunder{\text{eval}_3}9
  \quad
  x\mapsunder{\text{eval}_3}3
  \quad
  1\mapsunder{\text{eval}_3}1
\end{equation*}
and then extending linearly.
\begin{align*}
  \text{eval}_3(ax^2+bx+c)
   &=a\cdot\text{eval}_3(x^2)
     +b\cdot\text{eval}_3(x)
     +c\cdot\text{eval}_3(1)     \\
   &=9a+3b+c
\end{align*}
For instance,
$\text{eval}_3(x^2+2x+3)=9+6+3=18$.

\pause
On the basis elements, we can describe the action of this map as: 
plugging the value~$3$ in for $x$. 
That remains true when we extend linearly, so
$\text{eval}_3(\,p(x)\,)=p(3)$.
\end{frame}




%..........
\begin{frame}
\df[df:LinearTransformation]
\ExecuteMetaData[../map2.tex]{df:LinearTransformation}

\pause
\ex
For any vector space $V$ the \definend{identity} map $\map{\textrm{id}}{V}{V}$
given by $\vec{v}\mapsto\vec{v}$ is a linear transformation.
The check is easy.

\pause
\ex
In $\Re^3$ the function $f_{yz}$  
that reflects vectors over the $yz$-plane 
\begin{equation*}
  \colvec{x \\ y \\ z}\mapsunder{f_{yz}}\colvec{-x \\ y \\ z}
\end{equation*}
is a linear
transformation.
\begin{multline*}
  f_{yz}(r_1\colvec{x_1 \\ y_1 \\ z_1}+r_2\colvec{x_2 \\ y_2 \\ z_2})
  =f_{yz}(\colvec{r_1x_1+r_2x_2 \\ r_1y_1+r_2y_2 \\ r_1z_1+r_2z_2})  
  =\colvec{-(r_1x_1+r_2x_2) \\ r_1y_1+r_2y_2 \\ r_1z_1+r_2z_2}    \\
  =r_1\colvec{-x_1 \\ y_1 \\ z_1}+r_2\colvec{-x_2 \\ y_2 \\ z_2}  
  =r_1f_{yz}(\colvec{x_1 \\ y_1 \\ z_1})+r_2f_{yz}(\colvec{x_2 \\ y_2 \\ z_2}) 
\end{multline*}
\end{frame}



%..........
\begin{frame}
\lm[le:SpLinFcns]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:SpLinFcns}

\ExecuteMetaData[../map2.tex]{SpLinFcns}

\iftoggle{showallproofs}{
  \pause
  \pf\hspace*{-1em}
  \ExecuteMetaData[../map2.tex]{pf:SpLinFcns}
  \qed
}{
  \medskip
  \noindent The book contains the proof.
  \smallskip

  \ex We can combine the two homomorphisms $\map{f,g}{\polyspace_1}{\Re^2}$
  \begin{equation*}
    f(a_0+a_1x)=\colvec{a_0+a_1 \\ 0}
    \qquad
    g(a_0+a_1x)=\colvec{4a_1 \\ a_1}
  \end{equation*}
  into a function $\map{2f+3g}{\polyspace_1}{\Re^2}$
  whose action is this.
  \begin{equation*}
    (2f+3g)\,(a_0+a_1x)=\colvec{2a_0+14a_1 \\ 3a_1}
  \end{equation*}
  The point of the lemma is that $2f+3g$ is also a homomorphism
  (as is routine to check).
  The collection of homomorphisms from $\polyspace_1$ to $\Re^2$
  is closed under linear combinations of those homomorphisms\Dash it 
  is a vector space.
}
\end{frame}
\begin{frame}
\ex
Consider $\linmaps{\Re}{\Re^2}$.
A member of $\linmaps{\Re}{\Re^2}$ is a linear map. 
A linear map is determined by its action on a basis of the domain space.
Fix these bases.
\begin{equation*}
  B_{\Re}=\stdbasis_1=\sequence{1}
  \qquad
  B_{\Re^2}=\stdbasis_2=\sequence{\colvec{1 \\ 0}, 
                                \colvec{0 \\ 1}}
\end{equation*}
Thus the functions that are elements of $\linmaps{\Re}{\Re^2}$
are determined by $c_1$ and $c_2$ here.
\begin{equation*}
  1\mapsunder{t} c_1\colvec{1 \\ 0}+c_2\colvec{0 \\ 1}
\end{equation*}
We could write each such map as $h=h_{c_1,c_2}$.
There are two parameters and thus 
$\linmaps{\Re}{\Re^2}$ is a dimension~$2$ space.
% \pause
% \ex
% Similarly, for $\linmaps{\Re^2}{\Re^3}$, fix
% $\stdbasis_2=\sequence{\vec{e}_1, \vec{e}_2}$ and 
% $\stdbasis_3=\sequence{\textcolor{blue}{\vec{e}_1}, \textcolor{blue}{\vec{e}_2}, \textcolor{blue}{\vec{e}_3}}$
% (note that the blue ones are different; 
% they are three tall).
% We can characterize the elements 
% of $\linmaps{\Re^2}{\Re^3}$ in this way.
% \begin{equation*}
%   \vec{e}_1\mapsunder{t} c_1\textcolor{blue}{\vec{e}_1}+c_2\textcolor{blue}{\vec{e}_2}+c_3\textcolor{blue}{\vec{e}_3}
%   \qquad
%   \vec{e}_2\mapsunder{t} d_1\textcolor{blue}{\vec{e}_1}+d_2\textcolor{blue}{\vec{e}_2}+d_3\textcolor{blue}{\vec{e}_3}
% \end{equation*}
% So, $\linmaps{\Re^2}{\Re^3}$ is six-dimensional.
\end{frame}





% ..... Three.II.2 .....
\section{Range space and null space}
%..........
\begin{frame}
\lm[le:RangeIsSubSp]
\ExecuteMetaData[../map2.tex]{lm:RangeIsSubSp}

\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map2.tex]{pf:RangeIsSubSp}
  \qed
}{

  \bigskip
  The book has the proof; we instead consider an example.
}
\end{frame}

\begin{frame}
\ex
Let $\map{f}{\Re^2}{\matspace_{\nbyn{2}}}$ be  
\begin{equation*}
  \colvec{a \\ b}
  \mapsunder{f}
  \begin{mat}
    a  &a+b \\
    2b &b
  \end{mat}
\end{equation*}
(the check that it is a homomorphism is routine).
One subspace of the domain is the $x$~axis.
\begin{equation*}
  S=\set{\colvec{a \\ 0}\suchthat a\in\Re}
\end{equation*}
The image under~$f$ of the $x$~axis is a subspace of 
of the codomain~$\matspace_{\nbyn{2}}$.
\begin{equation*}
  f(S)=\set{
    \begin{mat}
      a &a \\
      0 &0
    \end{mat}
    \suchthat a\in\Re}
\end{equation*}

\pause
Another subspace of $\Re^2$ is $\Re^2$ itself.
The image of $\Re^2$ under $f$ is this subspace of~$\matspace_{\nbyn{2}}$.
\begin{equation*}
  f(\Re^2)=\set{
    \begin{mat}
      1 &1 \\
      0 &0
    \end{mat}\cdot c_1
    +
    \begin{mat}
      0 &1 \\
      2 &1
    \end{mat}\cdot c_2
    \suchthat c_1,c_2\in\Re}
\end{equation*}
% \ex
% For any angle $\theta$, 
% the function $\map{t_{\theta}}{\Re^2}{\Re^2}$ that rotates 
% vectors counterclockwise by $\theta$ is a homomorphism.
% In the domain~$\Re^2$ each line through the origin is a subspace.
% The image of that line under this map is another line through the origin, 
% a subspace of the codomain~$\Re^2$. 
\end{frame}


%..........
\begin{frame}{Range space}
\df[df:RangeSpace]
\ExecuteMetaData[../map2.tex]{df:RangeSpace}

\pause
\ex
This map from $\matspace_{\nbyn{2}}$ to $\Re^2$ is linear.
\begin{equation*}
  \begin{mat}
    a &b \\
    c &d
  \end{mat}
  \mapsunder{h}
  \colvec{a+b  \\ 2a+2b}
\end{equation*}
The range space is a line through the origin
\begin{equation*}
  \set{\colvec{t \\ 2t} \suchthat t\in\Re}
\end{equation*}
(every member of that set is the image 
\begin{equation*}
  \colvec{t \\ 2t}
  =
  h(
    \begin{mat}
      t  &0 \\
      0   &0
    \end{mat}
   )
\end{equation*}
of a $\nbyn{2}$ matrix).
The map's rank is $1$.
\end{frame}
\begin{frame}
% \ex
% The derivative map
% $\map{d/dx}{\polyspace_4}{\polyspace_4}$
% is linear.
% Its range is $\rangespace{d/dx}=\polyspace_3$.
% (Verifying that every member of $\polyspace_3$ is the derivative of some 
% member of $\polyspace_4$ is easy.)
% The rank of this derivative function is the dimension of $\polyspace_3$,
% namely~$4$. 

% \pause
\ex
Projection $\map{\pi}{\Re^3}{\Re^2}$
\begin{equation*}
  \colvec{x \\ y \\ z}\mapsto\colvec{x \\ y}
\end{equation*}
is a linear map; the check is routine.
The range space is $\rangespace{\pi}=\Re^2$
because given a vector $\vec{w}\in\Re^2$ 
\begin{equation*}
  \vec{w}=\colvec{a \\ b}
\end{equation*}
we can find a
$\vec{v}\in\Re^3$ that maps to it, specifically any $\vec{v}$ with a 
first component~$a$ and second component~$b$.
Thus the rank of $\pi$ is~$2$.
\end{frame}




%..........
\begin{frame}{Homomorphisms organize the domain}
In moving from isomorphisms to homomorphisms we dropped 
the requirement that the maps be onto and one-to-one.
Because any homomorphism $\map{h}{V}{W}$ is onto 
its range space $\rangespace{h}$,
dropping the onto condition has, in a way, no effect.

\pause
In contrast,
consider dropping the one-to-one condition.
Now there may be some vectors $\vec{w}\in W$
having many vectors $\vec{v}\in V$ mapped to $\vec{w}$.
(The drawing below shows only one maps-to arrow $\mapsto$ for all
the many domain elements, just to avoid a confused picture.) 
\centergraphic{../ch3.5}
\ExecuteMetaData[../map2.tex]{InverseImage}
\end{frame}
\begin{frame}
\ex
The projection map $\map{\pi}{\Re^2}{\Re}$ is linear.
\begin{equation*}
  \pi(\colvec{x \\ y})
  =x
\end{equation*}
\pause
Identify the codomain $\Re$ with the $x$-axis in $\Re^2$.
Here is an $x$-axis member, in red.
\centergraphic{asy/three_ii_proj1.pdf}
\pause
Next are some elements of $\pi^{-1}(2)$.
They are red because they are associated with $2$.
\centergraphic{asy/three_ii_proj2.pdf}
Think of these as ``$2$~vectors.''
The set of endpoints of all such vectors makes the line~$x=2$.
\end{frame}\begin{frame}
Here are some ``$3$-vectors,'' inverse images of $3$.
\centergraphic{asy/three_ii_proj3.pdf}
\pause
Projection is a homomorphism,
$\pi(\vec{u})+\pi(\vec{v})=\pi(\vec{u}+\vec{v})$.
Since  $\pi(\vec{u})=2$ and $\pi(\vec{v})=3$,
the sum $\vec{u}+\vec{v}$ will be mapped by $\pi$ to~$5$.
\centergraphic{asy/three_ii_proj5.pdf}
Thus, we can understand the definition of addition preservation as:
red plus blue makes purple\Dash a ``$2$ vector'' plus a
``$3$~vector'' sums to a ``$5$~vector.''

\pause
A similar interpretation holds for preservation of scalar multiplication.
\end{frame}




%..........
\begin{frame}
\ex
The projection $\map{\pi}{\Re^3}{\Re^2}$ is a homomorphism.
As above we can identify the codomain with the $xy$-plane inside of
$\Re^3$.
\only<1>{\centergraphic{asy/three_ii_3dproj1.pdf}}
\only<2>{\centergraphic{asy/three_ii_3dproj2.pdf}}
\only<3->{\centergraphic{asy/three_ii_3dproj3.pdf}}
In that codomain $xy$-plane the parallelogram shows a vector addition
$\vec{w}_1+\vec{w}_2=\vec{w}_3$.
We will illustrate that here also a $\vec{w}_1$ vector plus a
$\vec{w}_2$ vector equals a $\vec{w}_3$ vector.

\pause
The diagram shows some of the infinitely 
many points in each inverse image set~$\pi^{-1}(\vec{w}_i)$
(drawing all the points would show that each is a vertical line).
\pause
The sum of a vector $\vec{v}_1\in\pi^{-1}(\vec{w}_1)$ 
and a vector $\vec{v}_2\in\pi^{-1}(\vec{w}_2)$
equals a vector
$\vec{v}_3\in\pi^{-1}(\vec{w}_3)$.
\end{frame}




%..........
\begin{frame}
This interpretation of the definition of 
operation preservation also holds when the spaces are not 
ones that we can sketch.

\ex
Let $\map{h}{\polyspace_2}{\Re^2}$ be
\begin{equation*}
  ax^2+bx+c\mapsto\colvec{b \\ b}
\end{equation*}
and consider these three members of the range
\begin{equation*}
  \vec{w}_1=\colvec{1 \\ 1}\quad
  \vec{w}_2=\colvec{-1 \\ -1}\quad  
  \vec{w}_3=\colvec{0 \\ 0}
  \qquad \text{(note that $\vec{w}_1+\vec{w}_2=\vec{w}_3$).}
\end{equation*}
\pause
The inverse image of $\vec{w}_1$ is 
$h^{-1}(\vec{w}_1)=\set{a_1x^2+1x+c_1\suchthat a_1,c_1\in\Re^2}$.
% Example members are $3x^2+x+1$, $3x^2+x-4$, and $-2x^2+x$.
Members of this set are ``$\vec{w}_1$~vectors.''
\pause
The inverse image of $\vec{w}_2$ is 
$h^{-1}(\vec{w}_2)=\set{a_2x^2-1x+c_2\suchthat a_2,c_2\in\Re^2}$;
these are ``$\vec{w}_2$~vectors.''
The ``$\vec{w}_3$~vectors'' are members of
$h^{-1}(\vec{w}_3)=\set{a_3x^20x+c_3\suchthat a_3,c_3\in\Re^2}$.

\pause
Note that any $\vec{v}_1\in h^{-1}(\vec{w}_1)$
plus any $\vec{v}_2\in h^{-1}(\vec{w}_2)$
equals a $\vec{v}_3\in h^{-1}(\vec{w}_3)$.
(a quadratic with an $x$~coefficient of $1$ 
plus a quadratic with an $x$~coefficient of $-1$
equals a quadratic with an $x$~coefficient of~$0$).
\pause
A ``$\vec{w}_1$~vector'' plus a
``$\vec{w}_2$~vector'' is a ``$\vec{w}_3$~vector.'' 
\end{frame}





%..........
\begin{frame}{Null space}
In each of those examples, the homomorphism
$\map{h}{V}{W}$ shows how to view the domain $V$ as organized into the 
inverse images $h^{-1}(\vec{w})$.

In the examples these inverse images all look the same so if
we can describe one then we understand how the domain is 
divided. 
% We say ``organized'' because these inverse image sets 
% reflect the structure of the range
% in that a ``$\vec{w}_1$~vector'' plus a ``$\vec{w}_2$~vector'' 
% equals a ``$\vec{w}_1+\vec{w}_2$~vector,'' and likewise for 
% scalar multiplication.
\end{frame}


\begin{frame}
Vector spaces have a distinguished element, $\vec{0}$.
So we next consider the inverse image of that element $h^{-1}(\zero)$.
\lm[le:NullspIsSubSp]\hspace*{-1em}
\ExecuteMetaData[../map2.tex]{lm:NullspIsSubSp}


\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map2.tex]{pf:NullspIsSubSp}
  \qed
}{

  \medskip
  The book has the verification.
}

% \pause
% \medskip
% \no
% This result complements \nearbylemma{le:RangeIsSubSp}%
% that for any subspace of the domain its image is a subspace of the range.
\end{frame}




%..........
\begin{frame}
\df[df:NullSpace]
\ExecuteMetaData[../map2.tex]{df:NullSpace}

\centergraphic{../ch3.10}
\pause
\no 
Strictly, the trivial subspace of the codomain is not $\zero_{W}$, it is 
$\set{\zero_{W}}$, and
so we may think to write the nullspace as $h^{-1}(\set{\zero_{W}})$.
But we have defined the two sets $h^{-1}(\vec{w})$
and $h^{-1}(\set{\vec{w}})$ to be equal
and the first is easier to write.
\end{frame}




%..........
\begin{frame}
\ex
Consider the derivative $\map{d/dx}{\polyspace_2}{\polyspace_1}$.
This is the nullspace; note that it is a subset of the domain
\begin{equation*}
  \nullspace{d/dx}=\set{ax^2+bx+c \suchthat
                                  2ax+b=0}
\end{equation*}
(the `$0$' there is the zero polynomial $0x+0$).
Now, $2ax+b=0$ if and
only if they have the same constant coefficient 
$b=0$,
the same $x$~coefficient of $a=0$, and the same
coefficient of~$x^2$ (which gives no restriction).
So this is the nullspace, and the nullity is $1$. 
\begin{equation*}
  \nullspace{d/dx}=\set{ax^2+bx+c \suchthat
                                  a=0,\, b=0,\, c\in\Re}
                  =\set{c\suchthat c\in\Re}
\end{equation*}

\ex
The function $\map{h}{\Re^2}{\Re^1}$ given by
\begin{equation*}
  \colvec{a \\ b}\mapsto 2a+b
\end{equation*}
has this null space and so
its nullity is $1$.
\begin{equation*}
  \nullspace{h}
  =\set{\colvec{a \\ b}\suchthat 2a+b=0}
  =\set{\colvec{-1/2 \\ 1}b\suchthat b\in\Re}
\end{equation*}
\end{frame}
\begin{frame}
\ex
The homomorphism $\map{f}{\matspace_{\nbyn{2}}}{\Re^2}$
\begin{equation*}
  \begin{mat}
    a &b \\
    c &d 
  \end{mat}
  \mapsunder{f}
  \colvec{a+b \\ c+d}
\end{equation*}
has this null space
\begin{align*}
  \nullspace{f}
  &=\set{
    \begin{mat}
      a  &b  \\
      c  &d  
    \end{mat}
    \suchthat 
    \text{$a+b=0$ and $c+d=0$}
    }                                 \\
  &=\set{
    \begin{mat}
      -b  &b  \\
      -d  &d
    \end{mat}
    \suchthat
    b,d\in\Re
    }
\end{align*}
and a nullity of $2$.

\ex
The dilation function $\map{d_{3}}{\Re^2}{\Re^2}$
\begin{equation*}
  \colvec{a  \\ b}\mapsto\colvec{3a \\ 3b}
\end{equation*}
has
$\nullspace{d_{3}}=\set{\zero}$.
A trivial space has an empty basis so  $d_{3}$'s nullity is~$0$.
\end{frame}





%..........
\begin{frame}{Rank plus nullity}
\th[th:RankPlusNullEqDim]
\ExecuteMetaData[../map2.tex]{th:RankPlusNullEqDim}

\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim0}
  
  \pause
  \ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim1}
}{

  \medskip
  The book contains the proof.

  \ex Consider this map $\map{h}{\Re^3}{\Re}$.
  \begin{equation*}
    \colvec{x \\ y \\ z}\mapsunder{h} x/2+y/5+z  
  \end{equation*}
  The null space is this plane.
  \begin{equation*}
    \nullspace{h}=
     h^{-1}(0)
     =\set{\colvec{x \\ y \\ z}\suchthat x/2+y/5+z=0}
  \end{equation*}
  Other inverse image sets are also planes.
  \begin{equation*}
     h^{-1}(1)
     =\set{\colvec{x \\ y \\ z}\suchthat x/2+y/5+z=1}
     =\set{\colvec{x \\ y \\ z}\suchthat z=1-x/2-y/5}
  \end{equation*}
}
\end{frame}

\begin{frame}
\iftoggle{showallproofs}{
    \ExecuteMetaData[../map2.tex]{pf:RankPlusNullEqDim2}
    \qed
}{
  \noindent This shows the inverse images $h^{-1}(0)$ and $h^{-1}(1)$
  lined up on the $z$~axis.
  \begin{center}
    \includegraphics{asy/three_ii_kernel.pdf}
  \end{center}
  So~$h$ breaks the domain into stacked planes\Dash 
  any two inverse images $h^{-1}(r_1)$ and~$h^{-1}(r_2)$ are collections of
  domain vectors whose endpoints form a plane.
  The only difference between these $2$-dimensional subsets
  is where they sit in the stack,
  shown here as where they intersect $z$~axis.
  \pause
  That is, $h$ partitions the $3$-dimensional domain
  into   
  $2$-dimensional sets, leaving $1$ dimension of
  freedom,
  which matches the dimension of the map's range.
}
\end{frame}


\begin{frame}
\ex
Projection $\map{\pi}{\Re^3}{\Re^2}$ 
\begin{equation*}
  \colvec{a \\ b \\ c}\mapsto\colvec{a \\ b}
\end{equation*}
takes a $3$-dimensional domain
to a $2$-dimensional range.  
Its null space is the $z$-axis, so
its nullity is~$1$.

\pause
This example shows the idea of the proof particularly clearly.
Take 
the basis $B_N=\sequence{\vec{e}_3}$ for the null space. 
\pause
Expand that to the basis $\stdbasis_{3}$ for the entire domain.
\pause
On an input vector the action of $\pi$ is 
\begin{equation*}
  c_1\vec{e}_1+c_2\vec{e}_2+c_3\vec{e}_3
  \quad\mapsto\quad
  c_1\vec{e}_1+c_2\vec{e}_2+\zero
\end{equation*}
and so the domain is organized by~$\pi$ into inverse images 
that are vertical lines, one-dimensional sets 
like the null space.
\centergraphic{asy/three_ii_dims.pdf}
\end{frame}



\begin{frame}
\ex
The derivative function $\map{d/dx}{\polyspace_2}{\polyspace_1}$
\begin{equation*}
  ax^2+bx+c \mapsto 2a\cdot x+b
\end{equation*}
has this range space
\begin{equation*}
  \rangespace{d/dx}=\set{d\cdot x+e\suchthat d, e\in\Re}=\polyspace_{1}
\end{equation*}
(the linear polynomial $dx+e\in\polyspace_{1}$ 
is the image of any antiderivative $(d/2)x^2+ex+C$, where $C\in \Re$).
This is its null space.
\begin{equation*}
  \nullspace{d/dx}=\set{0x^2+0x+c \suchthat c\in\Re}=\set{c \suchthat c\in\Re}
\end{equation*}
The rank is $2$ while the nullity is~$1$, and they add to the domain's 
dimension~$3$.
% \pause
% \ex
% The function $\map{h}{\Re^2}{\Re^1}$ given by
% \begin{equation*}
%   \colvec{a \\ b}\mapsto 2a+b
% \end{equation*}
% has this range space
% \begin{equation*}
%   \rangespace{h}
%   =\set{2a+b\suchthat a,b\in\Re}
%   =\set{c\suchthat c\in\Re}
% \end{equation*}
% and this null space (calculated earlier).
% \begin{equation*}
%   \nullspace{h}
%   =\set{\colvec{-b/2 \\ b}\suchthat b\in\Re}
% \end{equation*}
% Its rank is $1$ and its nullity is $1$.
% Its domain $\Re^2$ has dimension~$2$.
\end{frame}
\begin{frame}
\ex
The dilation function $\map{d_{3}}{\Re^2}{\Re^2}$
\begin{equation*}
  \colvec{a  \\ b}\mapsto\colvec{3a \\ 3b}
\end{equation*}
has range space $\Re^2$
and a trivial nullspace
$\nullspace{d_{3}}=\set{\zero}$.
So its rank is~$2$
and its nullity is~$0$.
% \pause
% \ex
% The homomorphism $\map{f}{\matspace_{\nbyn{2}}}{\Re^2}$
% \begin{equation*}
%   \begin{mat}
%     a &b \\
%     c &d 
%   \end{mat}
%   \mapsunder{f}
%   \colvec{a+b \\ c+d}
% \end{equation*}
% has range space equal to $\Re^2$ (to get a vector with a first component of 
% $x$ and a second component of $y$ we can take $a=x$, $b=0$, $c=y$, and $d=0$).
% Thus $f$'s rank is~$2$.
% We found its null space earlier
% \begin{equation*}
%   \nullspace{f}
%   =\set{
%     \begin{mat}
%       -b  &b  \\
%       -d  &d
%     \end{mat}
%     \suchthat
%     b,d\in\Re
%     }
% \end{equation*}
% and its nullity is $2$.
\end{frame}




%..........
\begin{frame}
\lm[lm:ImageLinearlyDependentIsLinearlyDependent]
\ExecuteMetaData[../map2.tex]{lm:ImageLinearlyDependentIsLinearlyDependent}

\pause
\pf
\ExecuteMetaData[../map2.tex]{pf:ImageLinearlyDependentIsLinearlyDependent}
\qed

\pause
\ex
The trace function $\map{\trace}{\matspace_{\nbyn{2}}}{\Re}$
\begin{equation*}
  \begin{mat}
    a  &b  \\
    c  &d
  \end{mat}
  \mapsto a+d
\end{equation*}
is linear.
This set of matrices is dependent.
\begin{equation*}
  S=\set{
    \begin{mat}
      1  &0  \\
      0  &0
    \end{mat},\,
    \begin{mat}
      0  &1  \\
      0  &0
    \end{mat},\,
    \begin{mat}
      2  &1  \\
      0  &0
    \end{mat}
    }
\end{equation*}
The three matrices map to $1$, $0$, and $2$ respectively.
The set $\set{1,0,2}\subseteq\Re$ is linearly dependent.
\end{frame}




%..........
\begin{frame}{A one-to-one homorphism is an isomorphism}
\th[th:OOHomoEquivalence]
\ExecuteMetaData[../map2.tex]{th:OOHomoEquivalence}

\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence0}
}{
  \bigskip
  The book has the proof.
}
\end{frame}
\iftoggle{showallproofs}{
  \begin{frame}
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence1}

  \pause
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence2}
  \end{frame}
  \begin{frame}
  \ExecuteMetaData[../map2.tex]{pf:OOHomoEquivalence3}
  \qed
  \end{frame}
}{}



%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
