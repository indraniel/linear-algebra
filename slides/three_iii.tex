% see: https://groups.google.com/forum/?fromgroups#!topic/comp.text.tex/s6z9Ult_zds
\makeatletter\let\ifGm@compatii\relax\makeatother 
\documentclass[10pt,t]{beamer}
\usefonttheme{professionalfonts}
\usefonttheme{serif}
\PassOptionsToPackage{pdfpagemode=FullScreen}{hyperref}
\PassOptionsToPackage{usenames,dvipsnames}{color}
% \DeclareGraphicsRule{*}{mps}{*}{}
\usepackage{../linalgjh}
\usepackage{present}
\usepackage{xr}\externaldocument{../map3} % read refs from .aux file
\usepackage{xr}\externaldocument{../map1} % read refs from .aux file
\usepackage{xr}\externaldocument{../vs3} % read refs from .aux file
\usepackage{catchfilebetweentags}
\usepackage{etoolbox} % from http://tex.stackexchange.com/questions/40699/input-only-part-of-a-file-using-catchfilebetweentags-package
\makeatletter
\patchcmd{\CatchFBT@Fin@l}{\endlinechar\m@ne}{}
  {}{\typeout{Unsuccessful patch!}}
\makeatother

\mode<presentation>
{
  \usetheme{boxes}
  \setbeamercovered{invisible}
  \setbeamertemplate{navigation symbols}{} 
}
\addheadbox{filler}{\ }  % create extra space at top of slide 
\hypersetup{colorlinks=true,linkcolor=blue} 

\title[Computing Linear Maps] % (optional, use only with long paper titles)
{Three.III Computing Linear Maps}

\author{\textit{Linear Algebra} \\ {\small Jim Hef{}feron}}
\institute{
  \texttt{http://joshua.smcvt.edu/linearalgebra}
}
\date{}


\subject{Computing Linear Maps}
% This is only inserted into the PDF information catalog. Can be left
% out. 

\begin{document}
\begin{frame}
  \titlepage
\end{frame}

% =============================================
% \begin{frame}{Reduced Echelon Form} 
% \end{frame}



% ..... Three.III.1 .....
\section{Representing Linear Maps with Matrices}
%..........
\begin{frame}{\parbox[t]{\paperwidth}{Linear maps are determined by the action on a basis}}
Fix a domain space~$V$ 
with basis~$\sequence{\vec{\beta}_1,\ldots,\vec{\beta}_n}$, 
and a codomain space~$W$.
We've seen that to specify the action of a  
homomorphism $\map{h}{V}{W}$ on all domain vectors, we need only
specify its action
on the basis elements.
\begin{equation*}
  h(\vec{v})=h(c_1\cdot\vec{\beta}_1+\cdots+c_n\cdot\vec{\beta}_n)
            =c_1\cdot h(\vec{\beta}_1)+\cdots+c_n\cdot h(\vec{\beta}_n)
  \tag{$*$}
\end{equation*}
We've called this extending the action linearly from the basis to the entire 
domain. 
We now introduce a scheme for these calculations.

\pause\medskip
\ex
Let the domain be $V=\polyspace_2$ and the codomain be $W=\Re^2$,
with these bases.
\begin{equation*}
  B_{V}=\sequence{1,1+x,1+x+x^2}
  \qquad
  B_{W}
  =\sequence{\colvec{2 \\ 0}, \colvec{-1 \\ 1}}
\end{equation*}
Suppose that $\map{h}{\polyspace_2}{\Re^2}$ has this 
action on the domain basis.
\begin{equation*}
  h(1)=\colvec{0 \\ 1}
  \quad
  h(1+x)=\colvec{3 \\ 2}
  \quad
  h(1+x+x^2)=\colvec{-2 \\ -1}
\end{equation*}
\end{frame}
\begin{frame}
\noindent With this effect on the domain's basis,
\begin{equation*}
  h(\vec{\beta}_1)=\colvec{0 \\ 1}
  \quad
  h(\vec{\beta}_2)=\colvec{3 \\ 2}
  \quad
  h(\vec{\beta}_3)=\colvec{-2 \\ -1}
\end{equation*}
next find the
representation of the three outputs 
with respect to the codomain's basis $B_{W}$.
\begin{align*}
  &\rep{h(\vec{\beta}_1)}{B_{W}}
  =\colvec{1/2 \\ 1}
  \qquad\text{since }
  \colvec{0 \\ 1}=(1/2)\cdot\colvec{2 \\ 0}+1\cdot\colvec{-1 \\ 1}     \\
  &\rep{h(\vec{\beta}_2)}{B_{W}}
  =\colvec{5/2 \\ 2}
  \qquad\text{since }
  \colvec{3 \\ 2}=(5/2)\cdot\colvec{2 \\ 0}+2\cdot\colvec{-1 \\ 1}     \\
  &\rep{h(\vec{\beta}_3)}{B_{W}}
  =\colvec{-3/2 \\ -1}
  \qquad\text{since }
  \colvec{-2 \\ -1}=(-3/2)\cdot\colvec{2 \\ 0}-1\cdot\colvec{-1 \\ 1}   
\end{align*}
\pause
Summarize by writing those side-by-side.
\begin{equation*}
  \begin{mat}
    1/2 &5/2 &-3/2 \\
    1   &2   &-1
  \end{mat}
\end{equation*}
This is the matrix representation of~$h$ (with respect to $B_V,B_W$).
\end{frame}
\begin{frame}
The point of arranging those numbers in that way is that
if we start by representing a domain vector with respect to the domain's basis 
$\vec{v}=c_1\cdot\vec{\beta}_1+c_2\cdot\vec{\beta}_2+c_3\cdot\vec{\beta}_3$
% \begin{equation*}
%   \rep{\vec{v}}{B_{V}}=\colvec{c_1 \\ c_2 \\ c_3}
% \end{equation*}
and apply equation~($*$)
\begin{align*}
   h(c_1\vec{\beta}_1+c_2\vec{\beta}_2+c_3\vec{\beta}_3)  
   &=c_1\cdot h(\vec{\beta}_1)+c_2\cdot h(\vec{\beta}_2)+c_3\cdot h(\vec{\beta}_3) \\
    &=c_1\cdot\bigl((1/2)\cdot\colvec{2 \\ 0}+1\cdot\colvec{-1 \\ 1}\bigr)  \\
      &\quad +c_2\cdot\bigl((5/2)\cdot\colvec{2 \\ 0}+2\cdot\colvec{-1 \\ 1}\bigr)  \\
      &\quad +c_3\cdot\bigl((-3/2)\cdot\colvec{2 \\ 0}-1\cdot\colvec{-1 \\ 1}\bigr)
\end{align*}
then regrouping
\begin{equation*}
  =((1/2)c_1+(5/2)c_2-(3/2)c_3)\cdot\colvec{2 \\ 0}
  +(1c_1+2c_2-1c_3)\cdot\colvec{-1 \\ 1}         
\end{equation*}
expresses the image of $h(\vec{v})$ with respect to the codomain's 
basis.
\begin{equation*}
  \rep{h(\vec{v})}{B_{W}}
  =\colvec{(1/2)c_1+(5/2)c_2-(3/2)c_3 \\ 1c_1+2c_2-1c_3}
\end{equation*}
\end{frame}
\begin{frame}
\noindent
In summary, to represent application of the linear map
\begin{equation*}
  h(\vec{v})
\end{equation*}
we write the representation of the map next to the representation of
the input
\begin{equation*}
  \begin{mat}
    1/2 &5/2 &-3/2 \\
    1   &2   &-1
  \end{mat}_{B_V,B_W}
  \colvec{c_1 \\ c_2 \\ c_3}_{B_V}
\end{equation*}
and compute the representation of the output.
\begin{equation*}
  \rep{h(\vec{v})}{B_{W}}=\colvec{(1/2)c_1+(5/2)c_2-(3/2)c_3 \\ 1c_1+2c_2-1c_3}_{B_W}
\end{equation*}

\pause
The way the numbers combine to do this computation is:
take
the dot product of the rows of the representing matrix
with the single column 
representing the input,
to get the single column representing the output.
\end{frame}




%..........
\begin{frame}{Matrix representation of a linear map}
\df[def:MatRepMap]
\ExecuteMetaData[../map3.tex]{df:MatRepMap}

\pause
\medskip
(We often omit the matrix's subscript $B,D$.)
\end{frame}
\begin{frame}
\ex
Consider projection $\map{\pi}{\Re^2}{\Re^2}$ onto the $x$-axis.
\begin{equation*}
  \colvec{a \\ b}\mapsunder{\pi}\colvec{a \\ 0}
\end{equation*}
Let the domain and codomain bases be 
\begin{equation*}
  B=\sequence{\colvec{1 \\ 1}, \colvec{-1 \\ 1}}
  \qquad
  D=\sequence{\colvec{0 \\ 1}, \colvec{2 \\ 2}}
\end{equation*}
then by the computations 
\begin{align*}
  \colvec{1 \\ 1}\mapsunder{\pi}\colvec{1 \\ 0}
  &\quad\text{so}\quad
  \rep{\pi(\vec{\beta}_1)}{D}=\colvec{-1 \\ 1/2}     \\
  \colvec{-1 \\ 1}\mapsunder{\pi}\colvec{-1 \\ 0}
  &\quad\text{so}\quad
  \rep{\pi(\vec{\beta}_2)}{D}=\colvec{1 \\ -1/2}
\end{align*}
this is the matrix representation of $\pi$.
\begin{equation*}
  \rep{\pi}{B,D}=
  \begin{mat}
    -1  &1 \\
   1/2  &-1/2
  \end{mat}
\end{equation*}
\end{frame}
\begin{frame}
\ex
Again consider projection onto the $x$-axis
\begin{equation*}
  \colvec{a \\ b}\mapsunder{\pi}\colvec{a \\ 0}
\end{equation*}
but this time take the input and output bases to be the standard.
\begin{equation*}
  B=D=\stdbasis_2
  =\sequence{\colvec{1 \\ 0}, \colvec{0 \\ 1}}
\end{equation*}
We have
\begin{gather*}
  \colvec{1 \\ 0}\mapsunder{\pi}\colvec{1 \\ 0}
  \quad\text{ so }
  \rep{\pi(\vec{\beta}_1)}{D}=\colvec{1 \\ 0}               \\
  \colvec{0 \\ 1}\mapsunder{\pi}\colvec{0 \\ 0}
  \quad\text{ so }
  \rep{\pi(\vec{\beta}_2)}{D}=\colvec{0 \\ 0}
\end{gather*}
and this is $\rep{\pi}{\stdbasis_2,\stdbasis_2}$.
\begin{equation*}
  \begin{mat}
    1  &0  \\
    0  &0
  \end{mat}
\end{equation*}
\end{frame}

\begin{frame}
\ex Consider the domain~$\Re^2$ and the codomain~$\Re$.
Recall that with respect to the standard basis, a vector represents itself.
\begin{equation*}
  \rep{\colvec{-2 \\ 2}}{\stdbasis_2}=\colvec{-2 \\ 2}_{\stdbasis_2}
\end{equation*}
To represent $\map{h}{\Re^2}{\Re}$ 
\begin{equation*}
  \colvec{a \\ b}\mapsunder{h} 2a+3b
\end{equation*}
with respect to 
$\stdbasis_2$ and~$\stdbasis_1$,
first find the effect of $h$ on the domain's basis.
\begin{equation*}
  \colvec{1 \\ 0}\mapsto 2
  \qquad
  \colvec{0 \\ 1}\mapsto 3
\end{equation*}
Represent those with respect to the codomain's basis.
\begin{equation*}
  \rep{h(\vec{e}_1)}{\stdbasis_1}=\colvec{2}
  \qquad
  \rep{h(\vec{e}_2)}{\stdbasis_1}=\colvec{3}
\end{equation*}
This is $\nbym{1}{2}$ matrix representation.
\begin{equation*}
  H=\rep{h}{\stdbasis_2,\stdbasis_1}
  =
  \begin{mat}
    2 &3
  \end{mat}
\end{equation*}
\end{frame}




%..........
\begin{frame}\vspace*{-.5ex}
\th[th:MatMultRepsFuncAppl]
\ExecuteMetaData[../map3.tex]{th:MatMultRepsFuncAppl}
\end{frame}
\begin{frame}
\pf
This formalizes the example that began this subsection.
See \nearbyexercise{exer:MatVecMultRepLinMap}.
\qed

\pause
\medskip
\df[def:MatrixVecProd]
\ExecuteMetaData[../map3.tex]{df:MatrixVecProd}

\pause
\ex
We can perform the operation without any reference to spaces and bases.
\begin{equation*}
  \begin{mat}[r]
    3  &1  &2  \\
    0  &-2 &5
  \end{mat}
  \colvec[r]{4  \\ -1 \\ -3}
  =\colvec{3\cdot 4+1\cdot(-1)+2\cdot(-3) \\ 0\cdot 4-2\cdot(-1)+5\cdot(-3)}
  =\colvec[r]{5 \\ -13}
\end{equation*}
\end{frame}
\begin{frame}
\ex
Recall the matrix
representing 
projection $\map{\pi}{\Re^2}{\Re^2}$ onto the $x$-axis
\begin{equation*}  
  \rep{\pi}{B,D}=
  \begin{mat}
    -1  &1 \\
   1/2  &-1/2
  \end{mat}
\end{equation*}
% \begin{equation*}
%   \colvec{a \\ b}\mapsunder{\pi}\colvec{a \\ 0}
% \end{equation*}
with respect to these. 
\begin{equation*}
  B=\sequence{\colvec{1 \\ 1}, \colvec{-1 \\ 1}}\quad
  D=\sequence{\colvec{0 \\ 1}, \colvec{2 \\ 2}}
\end{equation*}
The domain vector 
\begin{equation*}
  \vec{v}=\colvec{-1 \\ 5}
\end{equation*} 
has this representation with respect to the domain basis.
\begin{equation*}
  \rep{\vec{v}}{B}=\colvec{2 \\ 3}
  \qquad
  \text{since 
  $2\cdot\colvec{1 \\ 1}+3\cdot\colvec{-1 \\ 1}=\colvec{-1 \\ 5}$}
\end{equation*}
\end{frame}
\begin{frame}
\noindent The matrix-vector product
gives the representation
\begin{equation*}
  \begin{mat}
    -1  &1 \\
    1/2  &-1/2
  \end{mat}
  \colvec{2 \\ 3}
  =\colvec{1 \\ -1/2}
  =\rep{\,\pi(\vec{v})\,}{D}
\end{equation*}
As a check,
\begin{equation*}
  1\cdot\colvec{0 \\ 1}-(1/2)\cdot\colvec{2 \\ 2}
  =\colvec{-1 \\ 0}
\end{equation*}
so it correctly computes the action of the projection map on the domain vector.
\begin{equation*}
  \pi(\,\colvec{-1 \\ 5}\,)=\colvec{-1 \\ 0}
\end{equation*}
\end{frame}

\begin{frame}
\ex Recall also that the map $\map{h}{\Re^2}{\Re}$ with this action
\begin{equation*}
  \colvec{a \\ b}\mapsunder{h} 2a+3b
\end{equation*}
is represented 
with respect to the standard bases $\stdbasis_2,\stdbasis_1$ by a
$\nbym{1}{2}$ matrix.
\begin{equation*}
  \rep{h}{\stdbasis_2,\stdbasis_1}
  =
  \begin{mat}
    2 &3
  \end{mat}
\end{equation*}
The domain vector
\begin{equation*}
  \vec{v}=\colvec{-2 \\ 2}
  \qquad
  \rep{\vec{v}}{\stdbasis_2}
  =\colvec{-2 \\ 2}
\end{equation*}
has this image.
\begin{equation*}
  \rep{h(\vec{v})}{\stdbasis_1}
  =
  \begin{mat}
    2 &3 
  \end{mat}
  \colvec{-2 \\ 2}
  =
  \colvec{2}_{\stdbasis_1}
\end{equation*}
Since this is a representation 
with respect to the standard basis $\stdbasis_1$,
meaning that vectors represent themselves, 
the image is $h(\vec{v})=2$.
\end{frame}






% ..... Three.III.2 .....
\section{Any Matrix Represents a Linear Map}
%..........
\begin{frame}
The prior subsection shows how to start with a linear map and produce its matrix
representation.
What about the converse?
\ex
Fix a matrix
\begin{equation*}
  H=\begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
\end{equation*}
and also fix a domain and codomain, with bases.
\begin{equation*}
  \stdbasis_2\subset\Re^2
  \quad
  \sequence{1-x,1+x}\subset\polyspace_1
\end{equation*}
Is there a linear map between the spaces associated with the matrix?

\pause
Consider $\map{h}{\Re^2}{\polyspace_1}$ defined by:
for any domain vector $\vec{v}$, represent it with respect to the domain basis
\begin{equation*}
  \vec{v}=c_1\vec{e}_1+c_2\vec{e}_2
  \qquad 
  \rep{\vec{v}}{E_2}=\colvec{c_1 \\ c_2}
\end{equation*}
multiply that representation by~$H$
\begin{equation*}
  \begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
  \colvec{c_1 \\ c_2}
  =\colvec{c_1+2c_2 \\ 3c_1+4c_2}
\end{equation*}
and then call $h(\vec{v})$ the codomain vector represented by
the result.
\begin{equation*}
  h(\vec{v})=(c_1+2c_2)\cdot (1-x)+(3c_1+4c_2)\cdot(1+x)
\end{equation*}
\end{frame}

\begin{frame}
Note first that $h$ is a function, that is, it is well-defined\Dash 
for a given input $\vec{v}$, the output $h(\vec{v})$ exists and is unique.
This is because
the representation of a vector with respect to a basis can be done in
one and only one way. 

\pause
We will now verify that $h$ is a linear function.
Fix domain vectors $\vec{u},\vec{v}\in\Re^2$ and represent them with 
respect to the domain basis. 
Multiply $c\cdot\rep{\vec{u}}{B}+d\cdot\rep{\vec{w}}{D}$ by $H$.
\begin{align*}
  \begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
  (c\cdot\colvec{u_1 \\ u_2}+d\cdot\colvec{v_1 \\ v_2})
  &=
  \begin{mat}
    1 &2 \\
    3 &4
  \end{mat}                              
  \colvec{cu_1+dv_1 \\ cu_2+dv_2}    \\
  &=
  \colvec{1(cu_1+dv_1)+2(cu_2+dv_2) \\ 3(cu_1+dv_1)+4(cu_2+dv_2)}   \\ 
  &=
  \colvec{1cu_1+2cu_2 \\ 3cu_1+4cu_2}  
  +
  \colvec{1dv_1+2dv_2 \\ 3dv_1+4dv_2}     \\              
  &=
  c\cdot\begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
  \colvec{u_1 \\ u_2}
  +
  d\cdot\begin{mat}
    1 &2 \\
    3 &4
  \end{mat}
  \colvec{v_1 \\ v_2}
\end{align*}
By the definition of $h$,
the result is $c\cdot\rep{h(\vec{u})}{D}+d\cdot\rep{h(\vec{v})}{D}$.
\end{frame}

\begin{frame}
\th[th:MatIsLinMap]
\ExecuteMetaData[../map3.tex]{th:MatIsLinMap}
\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map3.tex]{pf:MatIsLinMap}
  \qed
}{
 
  \bigskip
  The book has the proof.
}
\end{frame}




%..........
\begin{frame}
We will connect some properties of linear maps
with properties of the associated matrices.

First an easy one: 
observe that $\map{h}{V}{W}$ is the zero map $\vec{v}\mapsto\zero$
if and only
if it is represented, with respect to any bases, by the zero matrix.

\pause
For one direction, assume that $h$ is the zero map.
Then for any bases $B,D$ we have $h(\vec{\beta}_i)=\zero_W$, which is 
represented with respect to $D$ by the column vector of zeroes.
Thus $h$ is represented by the zero matrix.

\pause
For the other direction 
assume that there are bases $B,D$ such that $\rep{h}{B,D}$ is the zero
matrix.
For each $\vec{\beta}_i$ we have that $\rep{h(\vec{\beta}_1)}{D}$ is a
vector of zeros, and so $h(\vec{\beta}_i)$ is $\zero_W$.
Extending linearly gives that $h$ maps each $\vec{v}\in V$ to $\zero_W$,
and $h$ is the zero map.  

\pause
\ex The zero map $\map{z}{\Re^2}{\Re^3}$ is represented, 
with respect to any pair of bases,
by the $\nbym{2}{3}$
zero matrix.
\begin{equation*}
  Z=
  \begin{mat}
    0 &0 \\
    0 &0 \\
    0 &0
  \end{mat}
\end{equation*}

% \pause
% \medskip
% One thing this example does not illustrate is that typically a linear map
% will have many different matrices representing it, with respect to 
% the many different pairs of bases~$B,D$.
% A matrix property that derives from the map will be shared across
% all these representing matrices. 
\end{frame}




%..........
\begin{frame}
\th[th:RankMatEqRankMap]
\ExecuteMetaData[../map3.tex]{th:RankMatEqRankMap}
\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map3.tex]{pf:RankMatEqRankMap0}

  \pause
  \ExecuteMetaData[../map3.tex]{pf:RankMatEqRankMap1}
}{

  \bigskip
  The book has the proof.
}
\end{frame}
\iftoggle{showallproofs}{
  \begin{frame}
  \ExecuteMetaData[../map3.tex]{pf:RankMatEqRankMap2}
  \qed
  \end{frame}
}{}



%..........
\begin{frame}
\ex 
Consider the linear transformation $\map{t}{\Re^2}{\Re^2}$
given by
\begin{equation*}
  \colvec{a \\ b}\mapsto\colvec{2a-b \\ 2a-b}
\end{equation*}
Its range is the line~$x=y$ and so the rank of the map
is~$1$.
\pause
We will see two matrices representing this map,
the first with respect to these.
\begin{equation*}
  B=\sequence{\colvec{1 \\ 1}, \colvec{-1 \\ 1}},
  \quad
  D=\sequence{\colvec{1/2 \\ 0}, \colvec{0 \\ 1/3}}
\end{equation*}
This calculation is routine.
\begin{equation*}
  \rep{t(\vec{\beta}_1)}{D}=\rep{\colvec{1 \\ 1}}{D}=\colvec{2 \\ 3}
  \qquad
  \rep{\colvec{-3 \\ -3}}{D}=\colvec{-6 \\ -9}
\end{equation*}
The representing matrix has matrix rank~$1$ since the second row is $3/2$ of
the first.
\begin{equation*}
  \rep{t}{B,D}
  =
  \begin{mat}
    2  &-6  \\
    3  &-9  
  \end{mat}
\end{equation*}
\end{frame}
\begin{frame}
Still considering $\map{t}{\Re^2}{\Re^2}$
given by
\begin{equation*}
  \colvec{a \\ b}\mapsto\colvec{2a-b \\ 2a-b}
\end{equation*}
this time represent it with respect to the standard bases
$\stdbasis_3,\stdbasis_3$.
\begin{align*}
  &t(\vec{e}_1)=t(\colvec{1 \\ 0})=\colvec{2 \\ 2}
  \qquad \rep{\colvec{2 \\ 2}}{\stdbasis_2}=\colvec{2 \\ 2}  \\
  &t(\vec{e}_2)=t(\colvec{0 \\ 1})=\colvec{-1 \\ -1}
  \qquad \rep{\colvec{-1 \\ -1}}{\stdbasis_2}=\colvec{-1 \\ -1}
\end{align*}
(Remember that with respect to the standard basis, a vector represents itself.)
\begin{equation*}
  \rep{t}{\stdbasis_2,\stdbasis_2}
  =
  \begin{mat}
    2  &-1  \\
    2  &-1  
  \end{mat}
\end{equation*}
Gauss's Method on that matrix ends with one
nonzero row so it has matrix rank~$1$, as on the prior slide. 
\end{frame}




%..........
\begin{frame}
\co[cor:MatDescsMap]
\ExecuteMetaData[../map3.tex]{co:MatDescsMap}
\iftoggle{showallproofs}{
  \pause
  \pf
  \ExecuteMetaData[../map3.tex]{pf:MatDescsMap0}

  \pause
  \ExecuteMetaData[../map3.tex]{pf:MatDescsMap1}
  \qed
}{

  \bigskip
  The book has the proof.
  There are many examples in the section below.
}
\end{frame}



\begin{frame}
\ex
Any transformation rotating vectors 
counterclockwise by $\Theta$~radians $\map{t_\Theta}{\Re^2}{\Re^2}$ 
is represented with respect to the
standard bases by this matrix.
\begin{equation*}
  \rep{t_\Theta}{\stdbasis_2,\stdbasis_2}
  =
  \begin{mat}[r]
    \cos\Theta  &-\sin\Theta  \\
    \sin\Theta  &\cos\Theta
  \end{mat}
\end{equation*}
The $\Theta=\pi/4$ instance is
\begin{equation*}
  \rep{t_{\pi/4}}{\stdbasis_2,\stdbasis_2}
  =
  \begin{mat}[r]
    \sqrt{2}/2  &-\sqrt{2}/2  \\
    \sqrt{2}/2  &\sqrt{2}/2
  \end{mat}
  =(\sqrt{2}/2)\cdot
  \begin{mat}
    1  &-1  \\
    1  &1
  \end{mat}
\end{equation*}
and the rank of this matrix is two, reflecting
that the map $t_{\pi/4}$ is one-to-one and onto. 
\end{frame}




%..........
\begin{frame}
\df[df:NonsingularMap]
\ExecuteMetaData[../map3.tex]{df:NonsingularMap}
% \end{frame}




% %..........
% \begin{frame}
\pause
\lm[le:NonsingMatIffNonsingMap]
\ExecuteMetaData[../map3.tex]{le:NonsingMatIffNonsingMap}
\pause
\pf
\ExecuteMetaData[../map3.tex]{pf:NonsingMatIffNonsingMap0}

\pause
\ExecuteMetaData[../map3.tex]{pf:NonsingMatIffNonsingMap1}
\qed
\end{frame}




%..........
\begin{frame}
\ex
This matrix
\begin{equation*}
  \begin{mat}
    0  &3  \\
   -1  &2
  \end{mat}
\end{equation*}
is nonsingular since by inspection its two rows form a linearly independent
set.
So any map, with any domain and codomain, and represented by this matrix  
with respect to any pair of bases,
is an isomorphism.

\pause
\ex
Gauss's method shows that this matrix
\begin{equation*}
  \begin{mat}
    2  &1  &-2  \\
    3  &2  &1   \\
   -1  &0  &5
  \end{mat}
\end{equation*}
is singular so any map that it represents will be a homomorphism that
is not an isomorphism.
\end{frame}




%=======================================
\section{Finding Map Facts From the Matrix}



\begin{frame}{Review examples}
We will revisit some of the results about
representing a map with a matrix, and do a number of calculations that 
show how we can study the map with calculations on 
associated matrices.

\ex 
First, the number of rows and columns.
\begin{align*}
  \rep{h}{B,D}\cdot\rep{\vec{v}}{B}
  &=\rep{\vec{w}}{D}                  \\
  \begin{mat}
    1 &2 &3 \\ 
    4 &5 &6
  \end{mat}
  \colvec{x \\ y \\ z}
  &=
  \colvec{a \\ b}
\end{align*}
(Here and below we write representations
of the domain vector using $x$, $y$, etc., and 
representations of the codomain vector with $a$, $b$, etc.)

\pause
That equation has $H$ acting on three-tall vector inputs, and 
yielding two-tall vector outputs.
Matrix and vector entries combine by taking the
dot product of $H$'s rows with $\rep{\vec{v}}{B}$'s column.
So, given $H$ we can tell the dimension of the $h$'s domain because it
is the width of~$H$'s rows, in other words it is the number of columns in~$H$.
Similarly, the dimension of $h$'s codomain is the number of rows in~$H$.
\end{frame}

\begin{frame}
\ex Let $h$ be the transformation of~$\Re^2$ represented with respect to 
some bases by this matrix.
\begin{equation*}
  H=
  \begin{mat}
    1 &2 \\ 
    3 &4
  \end{mat}
\end{equation*}
This matrix has rank~$2$ since the second row is not a multiple
of the first.
\pause
Consider this equation.
\begin{align*}
  \rep{h}{B,D}\cdot\rep{\vec{v}}{B}
  &=\rep{\vec{w}}{D}                  \\
  \begin{mat}
    1 &2 \\ 
    3 &4
  \end{mat}
  \colvec{x \\ y}
  &=
  \colvec{a \\ b}
  \tag{$*$}
\end{align*}
We will solve this linear system for $x$ and~$y$ and then 
use that to understand 
why this map is onto, and why it is one-to-one.
\begin{multline*}
  \begin{amat}{2}
    1 &2  &a \\
    3 &4  &b
  \end{amat}
  \grstep{-3\rho_1+\rho_2}
  \begin{amat}{2}
    1 &2  &a \\
    0 &-2 &-3a+b
  \end{amat}                   \\    
  \grstep{-(1/2)\rho_2}        
  \begin{amat}{2}
    1 &2  &a \\
    0 &1  &(3/2)a-(1/2)b
  \end{amat}
  \grstep{-2\rho_2+\rho_1}
  \begin{amat}{2}
    1 &0  &-2a+b     \\
    0 &1  &(3/2)a-(1/2)b
  \end{amat}
\end{multline*}
\end{frame}

\begin{frame}
\begin{equation*}
  \begin{amat}{2}
    1 &2  &a \\
    3 &4  &b
  \end{amat}
  \grstep{-3\rho_1+\rho_2}
  \cdots\quad
  % \grstep{-(1/2)\rho_2}        
  % \grstep{-2\rho_2+\rho_1}
  \begin{amat}{2}
    1 &0  &-2a+b     \\
    0 &1  &(3/2)a-(1/2)b
  \end{amat}
\end{equation*}
\medskip

A function is onto if every member of the codomain~$\vec{w}$
is the image of at least one member~$\vec{v}$ of the domain.
The calculation shows that for all $\vec{w}$\Dash
for all representation entries $a,b\in\Re$\Dash there 
is an associated $\vec{v}$,
namely the domain member
represented with
$x=-2a+b$ and~$y=(3/2)a-(1/2)b$.
So $h$ is onto.

Thus $\rangespace{h}=\Re^2$, and so
the rank of~$h$ is as large as it could be,~$2$.

\pause
\medskip
A function is one-to-one if every member 
of the codomain~$\vec{w}$
is the image of at most one member~$\vec{v}$ of the domain.
The calculation shows that for all~$\vec{w}$,  
for all representing $a,b\in\Re$, the associated~$\vec{v}$
is unique, as represented by unique $x$ and~$y$.
So this~$h$ is one-to-one.

To compute the null space set $a=0$, $b=0$, giving 
the trivial domain subspace $x=0$, $y=0$.
So the nullity is~$0$.
(This is redundant given the prior paragraph since we know $\vec{0}_V$
maps to $\vec{0}_W$ and with the map being one-to-one, only one
domain vector is sent to $\vec{0}_W$, so it must be $\vec{0}_V$.)
\end{frame}


\begin{frame}{Leveraging existing tools}
The lesson is that 
we can fix bases and determine things about the map by doing
calculations with the representations of the map and vectors.

For instance, if we fix a basis~$B$ for the domain space~$V$ then every
vector $\vec{v}\in V$ is represented by one and only one column 
$\rep{\vec{v}}{B}$.
The same holds for the codomain vectors $\vec{w}\in W$.
So if we fix bases and calculate that for every output representation 
there exists an input representation, we have found that for 
every output vector there exists an input vector,
that the map is onto. 

We find working with the representations convenient because we have a bunch of 
tools, most notably Gauss's Method.

In these calculations, what is represented (polynomials, matrices, etc.)
is often not relevant.
Several examples below use maps between real spaces and with
respect to the standard bases so we can suppress the ``representation''
wording (because in such cases vector are their own representations).
\end{frame}



\begin{frame}
\ex   
Suppose that a map~$h$ between real spaces is represented by this.
\begin{equation*}
  H=
  \begin{mat}
    1 &2 &1 \\ 
    2 &3 &0
  \end{mat}
\end{equation*}
The domain has dimension~$3$ and the codomain has dimension~$2$
so $\map{f}{\Re^3}{\Re^2}$.
\pause
\begin{equation*}
  \begin{amat}{3}
    1 &2 &1  &a \\
    2 &3 &0  &b
  \end{amat}
  \grstep{-2\rho_1+\rho_2}
  \grstep{-\rho_2}
  \grstep{-2\rho_2+\rho_1}
  \begin{amat}{3}
    1 &0 &-3  &-3a+2b \\
    0 &1 &2   &2a-b
  \end{amat}
\end{equation*}
\pause
For each $a,b$ there is at least one triple
$x,y,z$ so this map is onto;
$\rank(h)=2$.

\pause 
For each $a,b$ there is more than one
triple $x,y,z$ so
this map is not one-to-one.
To find the null space set $a=0$, $b=0$.
\begin{equation*}
  \nullspace{h}
   =\set{\colvec{x \\ y \\ z}\suchthat \text{$y+2z=0$ and $x-3z=0$}}
   =\set{\colvec{3 \\ -2 \\ 1}z\suchthat z\in\Re}
\end{equation*}
The nullity is~$1$.
\end{frame}


\begin{frame}
\ex Let $h$ be the transformation of~$\Re^2$ represented with respect to the
standard bases $\stdbasis_2,\stdbasis_2$ by this matrix.
\begin{equation*}
  H=
  \begin{mat}
    1 &3 \\ 
    2 &6
  \end{mat}
\end{equation*}
The matrix rank is~$1$.
\begin{equation*}
  \begin{amat}{2}
    1 &3  &a \\
    2 &6  &b
  \end{amat}
  \grstep{-2\rho_1+\rho_2}
  \begin{amat}{2}
    1 &3  &a \\
    0 &0 &-2a+b
  \end{amat}                   
\end{equation*}
\pause
The map is not onto; $\rank(h)=1$.
\begin{equation*}
  \rangespace{h}
  =\set{\colvec{a \\ b}\suchthat -2a+b=0}
  =\set{\colvec{1/2 \\ 1}b\suchthat b\in\Re}
\end{equation*}
\pause
The map is also not one-to-one; $\nullity(h)=1$.
\begin{equation*}
  \nullspace{h}
  =\set{\colvec{x \\ y}\suchthat x+3y=0}
  =\set{\colvec{-3 \\ 1}y\suchthat y\in\Re}
\end{equation*}
Note that rank plus nullity equals the dimension of the domain.
\end{frame}

\begin{frame}
\ex
The definition of this map $\map{h}{\Re^3}{\Re^3}$  
\begin{equation*}
  \colvec{x \\ y \\ z}\mapsto\colvec{x \\ x+z \\ x-z}
\end{equation*}
shows that there is a restriction on which outputs are possible\Dash
the first component of the output is the average of
the other two\Dash so it is not onto.
It is not one-to-one because the output entries don't use~$y$,
so holding $x$ and~$z$ constant and varying~$y$ gives many inputs all
associated with the same output. 
We will do the calculations and see how those facts show themselves.

To represent~$h$ fix bases (we'll use the standard ones).
\begin{equation*}
  \colvec{1 \\ 0 \\ 0}\mapsto\colvec{1 \\ 1 \\ 1}
  \quad
  \colvec{0 \\ 1 \\ 0}\mapsto\colvec{0 \\ 0 \\ 0}
  \quad
  \colvec{0 \\ 0 \\ 1}\mapsto\colvec{0 \\ 1 \\ -1}
\end{equation*}
So $H$ is this.
\begin{equation*}
  \rep{h}{\stdbasis_3,\stdbasis_3}
  =
  \begin{mat}
    1 &0 &0 \\
    1 &0 &1 \\
    1 &0 &-1
  \end{mat}
\end{equation*}
\end{frame}
\begin{frame}
This calculation
\begin{equation*}
  \begin{amat}{3}
    1 &0 &0  &a \\
    1 &0 &1  &b \\
    1 &0 &-1 &c   
  \end{amat}
  \grstep[-\rho_1+\rho_3]{-\rho_1+\rho_2}
  % \begin{amat}{3}
  %   1 &0 &0  &a \\
  %   0 &0 &1  &-a+b \\
  %   0 &0 &-1 &-a+c   
  % \end{amat}
  \grstep{\rho_2+\rho_3}
  \begin{amat}{3}
    1 &0 &0  &a \\
    0 &0 &1  &-a+b \\
    0 &0 &0  &-2a+b+c   
  \end{amat}
\end{equation*}
shows that these are true.
\begin{align*}
  \rangespace{h}
   &=\set{\colvec{a \\ b \\ c}\suchthat a=(b+c)/2}    
   =\set{\colvec{1/2 \\ 1 \\ 0}b+\colvec{1/2 \\ 0 \\ 1}c\suchthat b,c\in\Re}    \\
  \nullspace{h}
   &=\set{\colvec{x \\ y \\ z}\suchthat \text{$x=0$ and $z=0$}}  
   =\set{\colvec{0 \\ 1 \\ 0}y\suchthat y\in\Re}
\end{align*}
By the first the map is not onto since the range space is not $3$~dimensional,
it is $2$~dimensional.
By the second the map is not one-to-one since the null space is not
$0$~dimensional, it is $1$~dimensional.
\end{frame}


\begin{frame}
\ex A linear map represented as here
\begin{equation*}
  H=
  \begin{mat}
    1 &2 \\
    1 &3 \\
    1 &4
  \end{mat}
\end{equation*}
has a dimension~$2$ domain and a dimension~$3$ codomain.
Then
\begin{equation*}
  \begin{amat}{2}
    1 &2 &a \\
    1 &3 &b \\
    1 &4 &c   
  \end{amat}
  \grstep[-\rho_1+\rho_3]{-\rho_1+\rho_2}
  \grstep{-2\rho_2+\rho_3}
  \grstep{-2\rho_2+\rho_1}
  \begin{amat}{2}
    1 &0 &3a-2b \\
    0 &1 &-a+b \\
    0 &0 &a-2b+c   
  \end{amat}
\end{equation*}
gives these.
\begin{align*}
  \rangespace{h}
  &=\set{\colvec{a \\ b \\ c}\suchthat a=2b-c}  \\
  \nullspace{h}
  &=\set{\colvec{x \\ y}\suchthat x=y=0}
\end{align*}
The map~$h$ is not onto but it is one-to-one.
\end{frame}

%...........................
% \begin{frame}
% \ExecuteMetaData[../gr3.tex]{GaussJordanReduction}
% \df[def:RedEchForm]
% 
% \end{frame}
\end{document}
